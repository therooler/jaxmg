{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "800acb1d",
   "metadata": {},
   "source": [
    "# Calling the solver in a `jax.shard_map` context\n",
    "\n",
    "\n",
    "The `potrs` interface uses a call to `jax.shard_map` to relayout the data in 1D cyclic form and call the underlying cuSolverMg API. In practice, one may have a more complicated jitted function that manipulates shards in a shard_map context already, which \n",
    "requires calling the solver within this function on individual shards.\n",
    "\n",
    "To allow for this use case, we also provide an API that has to be called in a shard_map context. \n",
    "Here, we rely on the user to correctly call `jax.shard_map`, passing the correct in and out shardings to their own function.\n",
    "\n",
    "In the example below, we use this API for a trivial matrix, now with `complex64` data type, where we apply a diagonal shift to to the \n",
    "matrix `A` before handing it to the solver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd9e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import jax.numpy as jnp\n",
    "from jax.sharding import PartitionSpec as P, NamedSharding\n",
    "from jaxmg import potrs_no_shardmap\n",
    "from functools import partial\n",
    "\n",
    "# Assumes we have at least one GPU available\n",
    "devices = jax.devices(\"gpu\")\n",
    "assert len(devices) in [1, 2], \"Example only works for 1 or 2 devices\"\n",
    "N = 8\n",
    "T_A = 2\n",
    "dtype = jnp.complex64\n",
    "# Create diagonal matrix and `b` all equal to one\n",
    "A = jnp.diag(jnp.arange(N, dtype=dtype) + 1)\n",
    "b = jnp.ones((N, 1), dtype=dtype)\n",
    "ndev = len(devices)\n",
    "# Make mesh and place data (columns sharded)\n",
    "mesh = jax.make_mesh((ndev,), (\"x\",))\n",
    "A = jax.device_put(A, NamedSharding(mesh, P(None, \"x\")))\n",
    "b = jax.device_put(b, NamedSharding(mesh, P(None, None)))\n",
    "diag_shift = 1e-1\n",
    "\n",
    "@partial(jax.jit, static_argnames=(\"_T_A\",))\n",
    "def shift_and_solve(_a, _b, _ds, _T_A):\n",
    "    idx = jnp.arange(_a.shape[0])\n",
    "    shard_size = _a.shape[1]\n",
    "    # Add shift based on index.\n",
    "    _a = _a.at[idx + shard_size * jax.lax.axis_index(\"x\"), idx].add(_ds)\n",
    "    jax.debug.print(\"dev{}:_a={}\", jax.lax.axis_index(\"x\"), _a)\n",
    "    # Call solver in shard_map context\n",
    "    return potrs_no_shardmap(_a, _b, _T_A)\n",
    "\n",
    "@partial(jax.jit, static_argnames=(\"_T_A\",))\n",
    "def jitted_potrs(_a, _b, _ds, _T_A):\n",
    "    out = jax.shard_map(\n",
    "        partial(shift_and_solve, _T_A=_T_A),\n",
    "        mesh=mesh,\n",
    "        in_specs=(P(None, \"x\"), P(None, None), P()),\n",
    "        out_specs=(P(None, None), P(None)),\n",
    "        check_vma=False\n",
    "    )(_a, _b, _ds)\n",
    "    return out\n",
    "\n",
    "out, status = jitted_potrs(A, b, diag_shift, T_A)\n",
    "print(f\"Status: {status}\")\n",
    "expected_out = 1.0 / (jnp.arange(N, dtype=dtype) + 1 + diag_shift)\n",
    "print(jnp.allclose(out.flatten(), expected_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b71f21",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "source": [
    "for two devices, this will print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49b17e6",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "source": [
    "\n",
    "> **Note:** `potrs_no_shardmap` always returns a status.\n",
    "\n",
    "> **Note:** Jax will complain about replication errors if you do not pass `check_vma=True`. This is likely because it cannot infer the output sharding from the ffi call."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
